***Human Action Classification Using 3D Convolutional Neural Network Using Video Data:***

**Motive:**

This documentation provides an overview of a Python script for video classification using a 3D Convolutional Neural Network (3DCNN). Using the video dataset, this Python script's primary goal is to classify human actions. The video dataset is essential for both the validation, training, and testing phases. \
This project's dataset was made available by the **_Center for Research in Computer Vision (UCF)_**. Hence, the dataset is named **UCF101**, Action Recognition. The dataset consists of 101 classes of human action.

**Why using 3DCNN?**

**3DCNN **is basically used for video classification. Itâ€™s similar with **2DCONV **just** **adding a third dimension on it. Moreover 2DCONV is basically fits best with static images while 3DCNN performs better on video. The use case of 3DCNN involves video data, medical imaging volumes (e.g., CT or MRI scans over time), and spatiotemporal data.

**Workflow Diagram:**
![Workflow Diagram]([https://drive.google.com/file/d/13PCR6dkWSEQPwa3RhqnUg2eadglYruJ-/view](https://1drv.ms/i/s!AlcfbF85V4zrbE1CBx_mWLtYv8Q?e=5SxtMu)https://1drv.ms/i/s!AlcfbF85V4zrbE1CBx_mWLtYv8Q?e=5SxtMu)
